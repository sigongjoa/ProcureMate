#!/usr/bin/env python3
"""
LLM ì‘ë‹µ ìƒì„¸ ì¡°íšŒ í•¸ë“¤ëŸ¬
"""

from typing import Dict, Any, Optional, List
from datetime import datetime
import json
from .handlers import get_status_handler
from utils import get_logger

logger = get_logger(__name__)

class LLMResponseHandler:
    """LLM ì‘ë‹µ ìƒì„¸ ì¡°íšŒ í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        self.status_handler = get_status_handler()
    
    async def get_llm_responses(self, limit: int = 20) -> Dict[str, Any]:
        """ìµœê·¼ LLM ì‘ë‹µë“¤ ì¡°íšŒ"""
        llm_tests = [
            test for test in self.status_handler.test_results 
            if test.test_type == "llm_analysis"
        ]
        
        llm_tests.sort(key=lambda x: x.timestamp, reverse=True)
        
        responses = []
        for test in llm_tests[:limit]:
            response_data = {
                "id": test.id,
                "timestamp": test.timestamp.isoformat(),
                "status": test.status,
                "input_query": test.input_data.get("query", ""),
                "llm_response": test.output_data,
                "response_time": test.metrics.response_time,
                "quality_score": test.metrics.quality_score,
                "error": test.error_message
            }
            responses.append(response_data)
        
        return {
            "responses": responses,
            "total": len(llm_tests),
            "limit": limit
        }

    
    async def get_llm_response_detail(self, test_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • LLM ì‘ë‹µ ìƒì„¸ ì¡°íšŒ"""
        test = await self.status_handler.get_test_detail(test_id)
        
        if not test or test.test_type != "llm_analysis":
            return None
        
        return {
            "id": test.id,
            "timestamp": test.timestamp.isoformat(),
            "status": test.status,
            "duration": test.duration,
            "input_data": test.input_data,
            "output_data": test.output_data,
            "metrics": test.metrics.dict(),
            "error_message": test.error_message,
            "formatted_response": self._format_llm_response(test.output_data)
        }

    
    def _format_llm_response(self, response_data: Dict[str, Any]) -> str:
        """LLM ì‘ë‹µì„ ì½ê¸° ì‰½ê²Œ í¬ë§·íŒ…"""
        if not response_data:
            return "ì‘ë‹µ ì—†ìŒ"
        
        if isinstance(response_data, dict):
            formatted = "=== LLM ë¶„ì„ ê²°ê³¼ ===\n\n"
            
            if "items" in response_data:
                formatted += f"ğŸ“¦ ìš”ì²­ ë¬¼í’ˆ: {', '.join(response_data['items'])}\n"
            
            if "quantities" in response_data:
                formatted += f"ğŸ“Š ìˆ˜ëŸ‰: {', '.join(response_data['quantities'])}\n"
            
            if "urgency" in response_data:
                formatted += f"âš¡ ê¸´ê¸‰ë„: {response_data['urgency']}\n"
            
            if "budget_range" in response_data:
                formatted += f"ğŸ’° ì˜ˆì‚° ë²”ìœ„: {response_data['budget_range']}\n"
            
            if "specifications" in response_data and response_data['specifications']:
                formatted += f"ğŸ“‹ ì‚¬ì–‘: {', '.join(response_data['specifications'])}\n"
            
            formatted += f"\n=== ì›ë³¸ JSON ===\n{json.dumps(response_data, indent=2, ensure_ascii=False)}"
            return formatted
        
        return str(response_data)

def get_llm_response_handler() -> LLMResponseHandler:
    """LLM ì‘ë‹µ í•¸ë“¤ëŸ¬ ì‹±ê¸€í†¤"""
    global _llm_response_handler
    if '_llm_response_handler' not in globals():
        globals()['_llm_response_handler'] = LLMResponseHandler()
    return globals()['_llm_response_handler']

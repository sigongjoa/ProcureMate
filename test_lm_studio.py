#!/usr/bin/env python3
"""LM Studio ì§ì ‘ í…ŒìŠ¤íŠ¸"""

import requests
import json

def test_lm_studio_connection():
    """LM Studio ì—°ê²° í…ŒìŠ¤íŠ¸"""
    
    server_url = "http://localhost:1234"
    
    print("=== LM Studio ì—°ê²° í…ŒìŠ¤íŠ¸ ===")
    
    # 1. ì„œë²„ ìƒíƒœ í™•ì¸
    print("1. ì„œë²„ ìƒíƒœ í™•ì¸...")
    try:
        response = requests.get(f"{server_url}/v1/models", timeout=5)
        print(f"   ìƒíƒœ ì½”ë“œ: {response.status_code}")
        print(f"   í—¤ë”: {dict(response.headers)}")
        print(f"   ì‘ë‹µ ê¸¸ì´: {len(response.text)}")
        print(f"   ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 200ì): {response.text[:200]}")
        
        if response.status_code == 200:
            models = response.json()
            print(f"   ëª¨ë¸ ìˆ˜: {len(models.get('data', []))}")
            if models.get('data'):
                for model in models['data']:
                    print(f"   - {model.get('id', 'Unknown')}")
            else:
                print("   âš ï¸ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        else:
            print(f"   âŒ ì˜¤ë¥˜ ì‘ë‹µ: {response.text}")
    except Exception as e:
        print(f"   âŒ ì—°ê²° ì‹¤íŒ¨: {e}")
        return False
    
    # 2. ì§ì ‘ ì±„íŒ… API í…ŒìŠ¤íŠ¸
    print("\n2. ì±„íŒ… API í…ŒìŠ¤íŠ¸...")
    try:
        payload = {
            "model": "llambricks-horizon-ai-korean-llama-3.1-1ft-dpo-8b",
            "messages": [{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}],
            "max_tokens": 50,
            "temperature": 0.7
        }
        
        print(f"   ìš”ì²­ í˜ì´ë¡œë“œ: {json.dumps(payload, indent=2, ensure_ascii=False)}")
        
        response = requests.post(
            f"{server_url}/v1/chat/completions",
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        print(f"   ìƒíƒœ ì½”ë“œ: {response.status_code}")
        print(f"   ì‘ë‹µ í—¤ë”: {dict(response.headers)}")
        print(f"   ì‘ë‹µ ë‚´ìš©: {response.text}")
        
        if response.status_code == 200:
            result = response.json()
            completion = result["choices"][0]["message"]["content"]
            print(f"   âœ… ì„±ê³µ! ì‘ë‹µ: {completion}")
            return True
        else:
            print(f"   âŒ ì˜¤ë¥˜: {response.text}")
            return False
            
    except Exception as e:
        print(f"   âŒ ì±„íŒ… API ì˜¤ë¥˜: {e}")
        return False

def test_llm_module():
    """LLM ëª¨ë“ˆ ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    print("\n=== LLM ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ===")
    
    import sys
    from pathlib import Path
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
    project_root = str(Path(__file__).parent)
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    
    try:
        from modules.llm_module import LlmModule
        
        llm = LlmModule()
        print("1. LLM ëª¨ë“ˆ ìƒì„± ì™„ë£Œ")
        
        # ì„œë²„ ìƒíƒœ í™•ì¸
        server_ok = llm.check_server_health()
        print(f"2. ì„œë²„ ìƒíƒœ: {'ì •ìƒ' if server_ok else 'ë¹„ì •ìƒ'}")
        
        if server_ok:
            # ì‹¤ì œ ìš”ì²­ í…ŒìŠ¤íŠ¸
            test_request = "ì‚¬ë¬´ìš© ì˜ì 5ê°œ í•„ìš”í•©ë‹ˆë‹¤"
            print(f"3. í…ŒìŠ¤íŠ¸ ìš”ì²­: {test_request}")
            
            analysis = llm.analyze_procurement_request(test_request)
            print(f"4. ë¶„ì„ ê²°ê³¼: {json.dumps(analysis, indent=2, ensure_ascii=False)}")
            
            return True
        else:
            print("   âŒ ì„œë²„ ìƒíƒœ ë¹„ì •ìƒìœ¼ë¡œ ì¸í•œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
            return False
            
    except Exception as e:
        print(f"   âŒ LLM ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("LM Studio ì—°ê²° ë° LLM ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\n")
    
    # 1. ì§ì ‘ ì—°ê²° í…ŒìŠ¤íŠ¸
    direct_ok = test_lm_studio_connection()
    
    # 2. ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    module_ok = test_llm_module()
    
    print("\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
    print(f"ì§ì ‘ ì—°ê²°: {'âœ… ì„±ê³µ' if direct_ok else 'âŒ ì‹¤íŒ¨'}")
    print(f"ëª¨ë“ˆ í…ŒìŠ¤íŠ¸: {'âœ… ì„±ê³µ' if module_ok else 'âŒ ì‹¤íŒ¨'}")
    
    if not direct_ok:
        print("\nğŸ”§ í•´ê²° ë°©ë²•:")
        print("1. LM Studioê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
        print("2. LM Studioì—ì„œ ëª¨ë¸ì„ ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸")
        print("3. LM Studioì˜ ë¡œì»¬ ì„œë²„ê°€ localhost:1234ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
        print("4. LM Studio ì„¤ì •ì—ì„œ CORSê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
